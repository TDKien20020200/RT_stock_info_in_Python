import yfinance as yf
from flask import request, render_template, jsonify, Flask
import matplotlib.pyplot as plt
import matplotlib

matplotlib.use('Agg')
from torchsummary import summary
from sklearn.preprocessing import MinMaxScaler
from torch.utils.data import TensorDataset, DataLoader
import torch
import torch.optim as optim
import torch.nn as nn
import numpy as np
import pandas as pd

app = Flask(name, template_folder='templates')

Xây dựng model Xác định kiến trúc: vì là vấn đề về chuỗi thời gian nên sẽ sử dụng Long Short-term Memory (LSTM) để nắm
bắt thông tin tuần tự:
class NeuralNetwork(nn.Module):
def init(self, num_feature):
super(NeuralNetwork, self).init()
self.lstm = nn.LSTM(num_feature, 64, batch_first=True)
self.fc = nn.Linear(64, num_feature)

Copy
def forward(self, x):
    output, (hidden, cell) = self.lstm(x)
    x = self.fc(hidden)
    return x
model = NeuralNetwork(4)

push to cuda if available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

Hàm Optimize Adam
optimizer = optim.Adam(model.parameters())

Hàm Loss MSELoss
mse = nn.MSELoss()

Mô hình Training: xác định quá trình thuận và nghịch (forward and backward) để train mạng lưới Neural:
def train(dataloader):
epoch_loss = 0
model.train()

Copy
for batch in dataloader:
    optimizer.zero_grad()
    x, y = batch
    pred = model(x)
    loss = mse(pred[0], y)
    loss.backward()
    optimizer.step()
    epoch_loss += loss.item()

return epoch_loss
Đánh giá hiệt suất mô hình
def evaluate(dataloader):
epoch_loss = 0
model.eval()

Copy
with torch.no_grad():
    for batch in dataloader:
        x, y = batch
        pred = model(x)
        loss = mse(pred[0], y)
        epoch_loss += loss.item()

return epoch_loss / len(dataloader)
@app.route('/')
def index():
return render_template('index.html')

@app.route('/ticker/<ticker>')
def ticker_detail(ticker):
data = yf.Ticker(ticker).history(period='1y')
dataYears = yf.Ticker(ticker).history(period='7y')
current_price = data.iloc[-1].Close
open_price = data.iloc[-1].Open
volume = data.iloc[-1].Volume

scheme
Copy
chart_data = {
    'x': data.index.strftime('%Y-%m-%d').tolist(),
    'open': data['Open'].tolist(),
    'high': data['High'].tolist(),
    'low': data['Low'].tolist(),
    'close': data['Close'].tolist()
}

# Filter and evaluate data
# Daily Chart
data.plot(subplots=True, figsize=(14.5, 6.5))
plt.savefig('./static/image/daily_chart.png')
# Weekly Chart
data.asfreq('W', method='ffill').plot(subplots=True, figsize=(14.5, 6.5), style='-')
plt.savefig('./static/image/weekly_chart.png')

# Calculate MAs
ma_day = [10, 20, 50]
for ma in ma_day:
    col_name = f'MA for {ma} days'
    data[col_name] = data['Close'].rolling(ma).mean()
data[['Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(figsize=(14.5, 6.5))
plt.title('Comparision some MA and Close')
plt.savefig('./static/image/MAs_chart.png')

# Dùng hàm pct_change() để tìm phần trăm thay đổi của giá Close mỗi ngày
data['Daily_Return'] = data['Close'].pct_change()
data.Daily_Return.plot(legend=True, figsize=(14.5, 6.5))
plt.title('Daily return percentage')
plt.savefig('./static/image/daily_return_chart.png')

###############################################################################################################
# Tạo dataset theo batch size trong pytorch
# Chuẩn hóa dữ liệu
data2 = data.copy(deep=True)
scaler = MinMaxScaler(feature_range=(0, 15)).fit(data2.Low.values.reshape(-1, 1))
data2['Open'] = scaler.transform(data2.Open.values.reshape(-1, 1))
data2['High'] = scaler.transform(data2.High.values.reshape(-1, 1))
data2['Low'] = scaler.transform(data2.Low.values.reshape(-1, 1))
data2['Close'] = scaler.transform(data2.Close.values.reshape(-1, 1))
normalizationData = data2[['Open', 'High', 'Low', 'Close']].values
# chuẩn bị dữ liệu cho bài toán dự đoán giá cổ phiếu dựa trên chuỗi thời gian. Nó tạo ra các chuỗi (sequences) dựa
# trên giá cổ phiếu từ 10 ngày trước để dự đoán giá cổ phiếu vào ngày tiếp theo
seq_len = 11
sequences = []
for index in range(len(normalizationData) - seq_len + 1):
    sequences.append(normalizationData[index: index + seq_len])
sequences = np.array(sequences)
# Customize dataset Tách dữ liệu toàn bộ tập dữ liệu thành ba phần. 80% cho tập huấn luyện (train), 10% cho tập xác
# thực (valid) và 10% còn lại cho tập kiểm thử (test):
valid_set_size_percentage = 10
test_set_size_percentage = 10

valid_set_size = int(np.round(valid_set_size_percentage / 100 * sequences.shape[0]))
test_set_size = int(np.round(test_set_size_percentage / 100 * sequences.shape[0]))
train_set_size = sequences.shape[0] - (valid_set_size + test_set_size)

x_train = sequences[:train_set_size, :-1, :]
y_train = sequences[:train_set_size, -1, :]

x_valid = sequences[train_set_size:train_set_size + valid_set_size, :-1, :]
y_valid = sequences[train_set_size:train_set_size + valid_set_size, -1, :]

x_test = sequences[train_set_size + test_set_size:, :-1, :]
y_test = sequences[train_set_size + test_set_size:, -1, :]
# DataLoader
# Tạo Trình tải dữ liệu: xác định các trình tải dữ liệu để tải tập dữ liệu theo từng batch với batch size = 32
x_train = torch.tensor(x_train).float()
y_train = torch.tensor(y_train).float()

x_valid = torch.tensor(x_valid).float()
y_valid = torch.tensor(y_valid).float()

train_dataset = TensorDataset(x_train, y_train)
train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False)

valid_dataset = TensorDataset(x_valid, y_valid)
valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False)

# Train mô hình trong 50 data sau đó sẽ lưu mô hình tốt nhất trong quá trình đào tạo dựa trên việc xác định Giá trị
# bị mất (Val Loss):
n_epochs = 100
best_valid_loss = float('inf')
for epoch in range(1, n_epochs + 1):
    train_loss = train(train_dataloader)
    valid_loss = evaluate(valid_dataloader)
    # save the best model
    if valid_loss < best_valid_loss:
        best_valid_loss = valid_loss
        torch.save(model, 'saved_weights.pt')
    # print("Epoch ",epoch+1)
    # print(f'\tTrain Loss: {train_loss:.5f} | ' + f'\tVal Loss: {valid_loss:.5f}\n')
# Từ kết quả trên suy ra đuợc mô hình tốt nhất, từ đó đưa ra vài dự đoán ban đầu
model = torch.load('saved_weights.pt')
x_test = torch.tensor(x_test).float()
with torch.no_grad():
    y_test_pred = model(x_test)
y_test_pred = y_test_pred.numpy()[0]
# visualize các dự đoán và so sánh chúng với thực tế:
idx = 0
plt.plot(np.arange(y_train.shape[0], y_train.shape[0] + y_test.shape[0]),
         y_test[:, idx], color='black', label='test target')

plt.plot(np.arange(y_train.shape[0], y_train.shape[0] + y_test_pred.shape[0]),
         y_test_pred[:, idx], color='green', label='test prediction')
plt.title('future stock prices')
plt.xlabel('time [days]')
plt.ylabel('normalized price')
plt.legend(loc='best')
plt.savefig('./static/image/predict_visualization.png')





@app.route('/tickers/analysis')
def tickers_analysis():
    tech_list = ['AAPL', 'GOOG', 'MSFT', 'AMZN']
    end = datetime.now()
    start = datetime(end.year - 2, end.month, end.day)
    data = {}

    now = datetime.now()
    date = now.strftime('%d') + now.strftime('%m')

    image_directory = './static/image/tickers/'
    for filename in os.listdir(image_directory):
        if filename.endswith('.png'):
            file_date = filename[-8:]
            if file_date[0:4] != date:
                file_path = os.path.join(image_directory, filename)
                os.remove(file_path)

    for stock in tech_list:
        data[stock] = yf.download(stock, start, end)
    company_list = tech_list
    company_name = ["APPLE", "GOOGLE", "MICROSOFT", "AMAZON"]

    for company, com_name in zip(company_list, company_name):
        data[company]['company_name'] = com_name

    df = pd.concat(data.values(), keys=data.keys(), axis=0)
    # Close chart
    filename1 = f'adj_close_chart_{date}.png'
    filepath1 = os.path.join('./static/image/tickers/', filename1)
    fileurl1 = url_for('static', filename=f'image/tickers/{filename1}')
    if not os.path.exists(filepath1):
        plt.figure(figsize=(15, 10))
        plt.subplots_adjust(top=1.25, bottom=1.2)
        for i, company in enumerate(company_list, 1):
            plt.subplot(2, 2, i)
            df.loc[company]['Adj Close'].plot()
            plt.ylabel('Adj Close')
            plt.xlabel(None)
            plt.title(f"Closing Price of {tech_list[i - 1]}")
        plt.tight_layout()
        plt.savefig(filepath1)
    # Volume chart
    filename2 = f'volume_chart_{date}.png'
    filepath2 = os.path.join('./static/image/tickers/', filename2)
    fileurl2 = url_for('static', filename=f'image/tickers/{filename2}')
    if not os.path.exists(filepath2):
        plt.figure(figsize=(15, 10))
        plt.subplots_adjust(top=1.25, bottom=1.2)
        for i, company in enumerate(company_list, 1):
            plt.subplot(2, 2, i)
            df.loc[company]['Volume'].plot()
            plt.ylabel('Volume')
            plt.xlabel(None)
            plt.title(f"Sales Volume for {tech_list[i - 1]}")
        plt.tight_layout()
        plt.savefig(filepath2)
    # MA (moving avage)
    ma_day = [10, 20, 50]
    for ma in ma_day:
        for company in company_list:
            column_name = f"MA for {ma} days"
            mean_value = df.loc[company, 'Adj Close'].rolling(ma).mean()
            df.loc[(company, slice(None)), column_name] = mean_value.values

    filename3 = f'MAs_chart_{date}.png'
    filepath3 = os.path.join('./static/image/tickers/', filename3)
    fileurl3 = url_for('static', filename=f'image/tickers/{filename3}')
    if not os.path.exists(filepath3):
        fig, axes = plt.subplots(nrows=2, ncols=2)
        fig.set_figheight(10)
        fig.set_figwidth(15)
        df.loc["AAPL"].plot(y=['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days'], ax=axes[0, 0])
        axes[0, 0].set_title('APPLE')
        df.loc["GOOG"].plot(y=['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days'], ax=axes[0, 1])
        axes[0, 1].set_title('GOOGLE')
        df.loc["MSFT"].plot(y=['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days'], ax=axes[1, 0])
        axes[1, 0].set_title('MICROSOFT')
        df.loc["AMZN"].plot(y=['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days'], ax=axes[1, 1])
        axes[1, 1].set_title('AMAZON')
        axes[0, 0].legend()
        axes[0, 1].legend()
        axes[1, 0].legend()
        axes[1, 1].legend()
        fig.tight_layout()
        plt.savefig(filepath3)
    # Daily return
    for company in company_list:
        change_pct = df.loc[company, 'Adj Close'].pct_change()
        df.loc[(company, slice(None)), 'Daily Return'] = change_pct.values

    filename4 = f'PC_line_chart_{date}.png'
    filepath4 = os.path.join('./static/image/tickers/', filename4)
    fileurl4 = url_for('static', filename=f'image/tickers/{filename4}')
    if not os.path.exists(filepath4):
        fig, axes = plt.subplots(nrows=2, ncols=2)
        fig.set_figheight(10)
        fig.set_figwidth(15)
        df.loc["AAPL"]['Daily Return'].plot(ax=axes[0, 0], legend=True, linestyle='--', marker='o')
        axes[0, 0].set_title('APPLE')
        df.loc["GOOG"]['Daily Return'].plot(ax=axes[0, 1], legend=True, linestyle='--', marker='o')
        axes[0, 1].set_title('GOOGLE')
        df.loc["MSFT"]['Daily Return'].plot(ax=axes[1, 0], legend=True, linestyle='--', marker='o')
        axes[1, 0].set_title('MICROSOFT')
        df.loc["AMZN"]['Daily Return'].plot(ax=axes[1, 1], legend=True, linestyle='--', marker='o')
        axes[1, 1].set_title('AMAZON')
        fig.tight_layout()
        plt.savefig(filepath4)

    filename5 = f'PC_column_chart_{date}.png'
    filepath5 = os.path.join('./static/image/tickers/', filename5)
    fileurl5 = url_for('static', filename=f'image/tickers/{filename5}')
    if not os.path.exists(filepath5):
        plt.figure(figsize=(12, 9))
        for i, company in enumerate(company_list, 1):
            plt.subplot(2, 2, i)
            df.loc[company, 'Daily Return'].hist(bins=50)
            plt.xlabel('Daily Return')
            plt.ylabel('Counts')
            plt.title(f'{company_name[i - 1]}')
        plt.tight_layout()
        plt.savefig(filepath5)
    # Correlation of adj close prices
    closing_df = pdr.get_data_yahoo(tech_list, start=start, end=end)['Adj Close']
    tech_rets = closing_df.pct_change()

    filename6 = f'comparations_visual_analysis_chart_{date}.png'
    filepath6 = os.path.join('./static/image/tickers/', filename6)
    fileurl6 = url_for('static', filename=f'image/tickers/{filename6}')
    if not os.path.exists(filepath6):
        sns.pairplot(tech_rets, kind='reg')
        plt.savefig(filepath6)

    filename7 = f'comparations_daily_return_chart_{date}.png'
    filepath7 = os.path.join('./static/image/tickers/', filename7)
    fileurl7 = url_for('static', filename=f'image/tickers/{filename7}')
    if not os.path.exists(filepath7):
        return_fig = sns.PairGrid(tech_rets.dropna())
        return_fig.map_upper(plt.scatter, color='purple')
        return_fig.map_lower(sns.kdeplot, cmap='cool_d')
        return_fig.map_diag(plt.hist, bins=30)
        plt.savefig(filepath7)

    filename8 = f'comparations_close_chart_{date}.png'
    filepath8 = os.path.join('./static/image/tickers/', filename8)
    fileurl8 = url_for('static', filename=f'image/tickers/{filename8}')
    if not os.path.exists(filepath8):
        returns_fig = sns.PairGrid(closing_df)
        returns_fig.map_upper(plt.scatter, color='purple')
        returns_fig.map_lower(sns.kdeplot, cmap='cool_d')
        returns_fig.map_diag(plt.hist, bins=30)
        plt.savefig(filepath8)

    filename9 = f'comparations_correlation_chart_{date}.png'
    filepath9 = os.path.join('./static/image/tickers/', filename9)
    fileurl9 = url_for('static', filename=f'image/tickers/{filename9}')
    if not os.path.exists(filepath9):
        plt.figure(figsize=(12, 10))
        plt.subplot(2, 2, 1)
        sns.heatmap(tech_rets.corr(), annot=True, cmap='summer')
        plt.title('Correlation of stock return')
        plt.subplot(2, 2, 2)
        sns.heatmap(closing_df.corr(), annot=True, cmap='summer')
        plt.title('Correlation of stock closing price')
        plt.savefig(filepath9)
    # Risk
    filename10 = f'risks_chart_{date}.png'
    filepath10 = os.path.join('./static/image/tickers/', filename10)
    fileurl10 = url_for('static', filename=f'image/tickers/{filename10}')
    if not os.path.exists(filepath10):
        rets = tech_rets.dropna()
        area = np.pi * 20
        plt.figure(figsize=(10, 8))
        plt.scatter(rets.mean(), rets.std(), s=area)
        plt.xlabel('Expected return')
        plt.ylabel('Risk')
        for label, x, y in zip(rets.columns, rets.mean(), rets.std()):
            plt.annotate(label, xy=(x, y), xytext=(50, 50), textcoords='offset points', ha='right', va='bottom',
                         arrowprops=dict(arrowstyle='-', color='blue', connectionstyle='arc3,rad=-0.3'))
        plt.savefig(filepath10)

    return render_template('tickers_analysis.html', tech_list=tech_list, fileurl1=fileurl1, fileurl2=fileurl2,
                           fileurl3=fileurl3, fileurl4=fileurl4, fileurl5=fileurl5, fileurl6=fileurl6,
                           fileurl7=fileurl7,
                           fileurl8=fileurl8, fileurl9=fileurl9, fileurl10=fileurl10)

data = data.tail(30)
data_list = data.reset_index().to_dict(orient='records')

return render_template('ticker_detail.html', ticker=ticker, current_price=current_price, open_price=open_price,
                       volume=volume, data_list=data_list, chart_data=chart_data)
@app.route('/get_stock_data', methods=['POST'])
def get_stock_data():
ticker = request.get_json()['ticker']
data = yf.Ticker(ticker).history(period='1y')
return jsonify({'currentPrice': data.iloc[-1].Close,
'openPrice': data.iloc[-1].Open})

if name == 'main':
app.run(debug=True)